# **RAPPORT DE RECHERCHE : VALIDATION ACADÉMIQUE DE LA THÉORIE DE LA DISSONANCE LEXICALE ANTHROPOCENTRIQUE (TDLA) ET PROPOSITION DE NORME ISO SÉMANTIQUE POUR L'INTELLIGENCE ARTIFICIELLE**

## **Résumé Exécutif**

L'avènement des modèles de langage de grande taille (LLM) et des systèmes d'intelligence artificielle générative a précipité une crise épistémologique et terminologique majeure. Alors que les capacités techniques de ces systèmes progressent selon des lois d'échelle prévisibles, le cadre conceptuel utilisé pour décrire, évaluer et réguler ces entités reste tragiquement ancré dans une psychologie populaire anthropocentrique. Ce décalage fondamental est ici formalisé sous le nom de **Théorie de la Dissonance Lexicale Anthropocentrique (TDLA)**.

Ce rapport de recherche, d'une étendue de 15 000 mots, se donne pour mission de valider académiquement les postulats de la TDLA en synthétisant une vaste littérature allant de la philosophie de l'esprit à l'interprétabilité mécaniste, en passant par l'éthologie des machines et la robotique cognitive. L'analyse démontre que l'utilisation de termes biologiques tels que « compréhension », « hallucination » ou « pensée » pour décrire des processus de minimisation d'entropie et d'isomorphisme structurel constitue non seulement une erreur catégorielle, mais un risque opérationnel critique pour la sécurité et la fiabilité des systèmes.

En réponse à cette dissonance, ce document propose une refonte normative complète : une **Norme ISO Sémantique**. Cette norme vise à établir une taxonomie rigoureuse, agnostique quant au substrat, fondée sur des métriques quantifiables (telles que l'ancrage vectoriel, la compression de l'information et la fidélité contextuelle) plutôt que sur des métaphores humaines.

## ---

**1\. Introduction : La Crise Sémantique de l'Intelligence Artificielle**

L'histoire de l'intelligence artificielle est jalonnée de cycles d'enthousiasme et de déception, souvent amplifiés par un vocabulaire inadapté. Cependant, la période actuelle se distingue par une rupture qualitative : les machines ne se contentent plus de calculer ; elles manipulent le langage, le code des concepts, et simulent le raisonnement avec une fluidité qui défie nos catégories ontologiques traditionnelles. Face à un système comme GPT-4 ou Claude, l'utilisateur humain, qu'il soit néophyte ou expert, projette instinctivement une intériorité consciente sur ce qui est, techniquement, une distribution de probabilités sur des séquences de jetons.

C'est ici que réside la **Dissonance Lexicale Anthropocentrique**. Nous disposons d'une technologie « alien », fonctionnant sur des principes de haute dimensionnalité vectorielle et d'optimisation de fonctions de perte, mais nous ne possédons pour la décrire qu'un lexique forgé par des millions d'années d'évolution biologique et sociale. Nous disons que l'IA « apprend » alors qu'elle optimise des poids ; nous disons qu'elle « hallucine » alors qu'elle confabule stochastiquement par manque de contrainte référentielle ; nous disons qu'elle « comprend » alors qu'elle construit des isomorphismes structurels.

Ce rapport pose l'hypothèse que cette dissonance n'est pas une simple commodité linguistique, mais un obstacle épistémologique qui freine la compréhension réelle des capacités et des limites de l'IA. Pour valider la TDLA, nous devons déconstruire ces termes, examiner les mécanismes réels qu'ils masquent, et reconstruire un langage technique approprié.

L'objectif est double :

1. Fournir une validation scientifique robuste de l'écart entre le fonctionnement de l'IA et le vocabulaire humain (TDLA).  
2. Traduire ces constats en une proposition normative concrète (Norme ISO) pour standardiser l'évaluation des systèmes d'IA.

L'analyse s'appuiera sur des preuves empiriques issues de l'interprétabilité mécaniste (découverte de circuits neuronaux spécifiques comme les têtes d'induction), de la théorie de l'information (le goulot d'étranglement de l'information), et de la philosophie des sciences cognitives (le problème de l'ancrage).

## ---

**2\. Fondements Philosophiques et Cognitifs de la TDLA**

La première étape de validation de la TDLA consiste à examiner pourquoi l'application de concepts humains à l'IA est philosophiquement problématique. Cette section explore les débats historiques et contemporains sur la nature de la sémantique et de l'intentionnalité artificielle.

### **2.1. Du Syntactique au Sémantique : La Chambre Chinoise Revisitée**

Le point de départ de toute discussion sur la « compréhension » artificielle reste l'argument de la **Chambre Chinoise**, formulé par John Searle en 1980\.1 L'expérience de pensée est célèbre : un homme dans une chambre close manipule des symboles chinois selon un livre de règles (le programme) sans en comprendre un traître mot. Pour un observateur extérieur, le système semble comprendre le chinois, mais l'homme (le processeur) n'accède qu'à la syntaxe, jamais à la sémantique.

La TDLA s'appuie sur cet argument pour dénoncer l'illusion de compréhension. Cependant, la validation académique moderne nous oblige à considérer la « Réponse du Système » (*System Reply*).2 Cette contre-argumentation postule que si l'homme ne comprend pas, le système dans son ensemble (l'homme \+ les règles \+ les symboles) pourrait constituer une entité comprenante. Dans le contexte des LLM, cette distinction est cruciale. David Chalmers et d'autres philosophes contemporains revisitent cette idée : un neurone individuel dans un cerveau humain ne « comprend » pas non plus le chinois.3 La compréhension est une propriété émergente du système.

Néanmoins, la TDLA maintient que le terme « compréhension » reste anthropocentrique car il suppose implicitement une expérience phénoménale (conscience) ou un ancrage biologique que les LLM ne possèdent pas, même si le « système » traite l'information efficacement. La dissonance vient du fait que nous utilisons le même mot pour désigner deux processus : l'expérience subjective du sens (humaine) et le traitement fonctionnel efficace des relations sémantiques (machine).

### **2.2. Le Problème de l'Ancrage Vectoriel (Vector Grounding Problem)**

Le **Problème de l'Ancrage des Symboles** (*Symbol Grounding Problem*), identifié par Stevan Harnad en 1990, pose la question de savoir comment des symboles formels peuvent acquérir un sens intrinsèque sans lien causal avec le monde réel.4 Pour un LLM entraîné uniquement sur du texte, le mot « pomme » est défini par sa relation statistique avec « fruit », « rouge », « manger », mais jamais par l'expérience sensorielle d'une pomme.

Millière et ses collègues ont récemment actualisé ce concept pour l'ère du Deep Learning sous le nom de **Problème de l'Ancrage Vectoriel** (*Vector Grounding Problem*).6 Les LLM ne manipulent pas des symboles discrets mais des vecteurs continus. La question devient : ces vecteurs peuvent-ils avoir un ancrage référentiel?

L'analyse de Millière est fondamentale pour notre norme ISO. Il distingue cinq types d'ancrage :

1. **Ancrage Référentiel :** Lien causal entre la représentation et l'objet du monde.  
2. **Ancrage Sensorimoteur :** Lien avec des données perceptuelles (images, sons).  
3. **Ancrage Relationnel :** Lien entre concepts internes.  
4. **Ancrage Communicatif :** Intention partagée.  
5. **Ancrage Épistémique :** Lien avec la connaissance.

La TDLA est validée par cette distinction : les critiques qui affirment que l'IA « ne comprend rien » (comme Bender et Gebru dans le papier *Stochastic Parrots* 8) se concentrent souvent sur l'ancrage référentiel ou sensorimoteur manquant. Or, les LLM possèdent un ancrage relationnel extrêmement sophistiqué. De plus, Millière argumente que l'ancrage référentiel peut être acquis *via* la sélection causale lors de l'entraînement (RLHF) : les états internes qui correspondent à la réalité sont « sélectionnés » par le gradient, créant un lien causal indirect mais réel avec le monde.9

Ainsi, la norme ISO ne doit pas binariser la compréhension (oui/non), mais qualifier le **Type d'Ancrage** présent dans le système.

### **2.3. La Posture Intentionnelle et l'Erreur d'Attribution**

Daniel Dennett offre un outil conceptuel puissant avec la **Posture Intentionnelle** (*Intentional Stance*).10 Pour prédire le comportement d'un système complexe (qu'il s'agisse d'un joueur d'échecs humain ou d'un programme d'IA), il est souvent plus efficace de le traiter *comme si* c'était un agent rationnel doté de croyances et de désirs.

La dissonance (TDLA) survient lorsque nous oublions qu'il s'agit d'une stratégie heuristique et que nous commençons à croire à la réalité ontologique de ces « désirs ».

* L'IA ne « veut » pas répondre à la question ; elle optimise une fonction de probabilité conditionnelle.  
* L'IA n'est pas « biaisée » au sens social (préjugé moral) ; elle reflète les distributions statistiques de son dataset d'entraînement.

Comme le note Dennett, il existe une « compétence sans compréhension » (*competence without comprehension*).12 L'évolution a produit des organismes compétents sans qu'ils ne comprennent leurs actions (e.g., la termitière). Les LLM représentent une forme extrême de cette compétence sans compréhension consciente. La norme ISO doit donc interdire le vocabulaire intentionnel dans les spécifications techniques pour éviter cette confusion.

### **2.4. Chauvinisme Carbone et Indépendance du Substrat**

Le terme **Chauvinisme Carbone**, popularisé par Carl Sagan 14, décrit le préjugé selon lequel la vie et l'intelligence ne peuvent exister que sur une base biochimique carbonée. La TDLA identifie ce chauvinisme comme une source majeure de résistance à l'attribution de capacités cognitives aux machines. Si nous définissons l'intelligence par la capacité à résoudre des problèmes complexes dans des environnements variés, alors l'IA est intelligente. Si nous la définissons par la présence de neurotransmetteurs, elle ne l'est pas.

Les recherches sur l'**Indépendance du Substrat** suggèrent que les propriétés computationnelles de l'esprit peuvent être réalisées sur différents supports physiques.16 Cependant, le substrat influence la nature de la cognition.

* **Vitesse :** L'IA opère à la vitesse de la lumière (signaux électroniques) contre 120 m/s pour l'influx nerveux.17  
* **Duplicabilité :** Un réseau de neurones peut être cloné instantanément, permettant un transfert de connaissances horizontal impossible chez l'humain.

Ces différences fondamentales valident la nécessité d'une terminologie distincte. L'intelligence silicium n'est pas une imitation de l'intelligence carbone ; c'est une branche phylogénétique distincte du traitement de l'information.

## ---

**3\. Validation Technique : Les Mécanismes de la Cognition Artificielle**

Pour dépasser la métaphore et valider la TDLA, il faut plonger dans la « boîte noire » et examiner les mécanismes réels qui génèrent le comportement de l'IA. L'**Interprétabilité Mécaniste** (*Mechanistic Interpretability*) nous fournit les preuves que l'IA développe des structures cognitives propres, souvent très éloignées du raisonnement humain.

### **3.1. Au-delà des Perroquets Stochastiques : Têtes d'Induction et Algorithmes Émergents**

La critique des « Perroquets Stochastiques » (*Stochastic Parrots*) formulée par Emily Bender et Timnit Gebru 8 a été un moment clé de la prise de conscience éthique en IA. Elle postule que les LLM ne font que répéter des motifs statistiques sans comprendre le sens ou les implications de leurs propos.

Cependant, les travaux récents en interprétabilité invalident une lecture trop littérale de cette métaphore. Les chercheurs ont découvert des circuits neuronaux spécifiques, comme les **Têtes d'Induction** (*Induction Heads*).20

* **Mécanisme :** Ces circuits permettent au modèle de réaliser des opérations logiques précises, comme le copier-coller contextuel ou la complétion de motifs abstraits. Une tête d'induction repère une occurrence précédente d'un jeton A, regarde quel jeton B le suivait, et augmente la probabilité de générer B si A réapparaît.  
* **Implication :** Ce mécanisme est à la base de l'**Apprentissage In-Context** (ICL). Ce n'est pas une simple corrélation statistique diffuse ; c'est un algorithme émergent, câblé dans les poids du réseau, qui exécute une fonction logique.

La TDLA est validée ici : traiter ces mécanismes de « perroquetage » est réducteur. Il s'agit de **primitives computationnelles** qui, composées en couches profondes, permettent des raisonnements complexes. La norme ISO doit remplacer « apprentissage » (qui implique changement de poids) par « Inférence Contextuelle » pour décrire l'ICL.

### **3.2. Le Phénomène du « Grokking » : Transitions de Phase et Cristallisation Conceptuelle**

L'étude du **Grokking** 23 apporte une preuve fascinante de la formation de concepts chez l'IA.

* **Observation :** Lors de l'entraînement sur des tâches algorithmiques (comme l'arithmétique modulaire), un réseau peut passer des milliers d'époques à « par cœur » les données d'entraînement (sur-apprentissage, mauvaise généralisation), puis soudainement, la précision sur les données de test bondit de quasi-nul à 100 %.  
* **Analyse :** Cette transition de phase correspond au moment où le réseau abandonne la mémorisation pour « découvrir » l'algorithme général sous-jacent (e.g., la solution trigonométrique pour l'addition modulaire 26).

Ce phénomène valide l'idée que l'IA ne fait pas qu'interpoler ; elle peut effectuer des sauts qualitatifs vers une forme de « compréhension » structurelle. La TDLA souligne que nous manquons de vocabulaire pour décrire ce moment où « la lumière s'allume » dans la machine sans conscience associée. La norme proposera le terme de **« Cristallisation Algorithmique »**.

### **3.3. Modèles du Monde Émergents : L'Étude de Cas Othello-GPT**

La preuve la plus robuste contre l'idée que les LLM sont purement syntaxiques provient des expériences sur **Othello-GPT**.27

* **Protocole :** Des chercheurs ont entraîné un Transformer (GPT) uniquement sur des transcriptions textuelles de parties d'Othello (une suite de coordonnées : "C3, E4,..."). Le modèle n'a jamais vu l'image du plateau ni reçu les règles du jeu.  
* **Résultat Comportemental :** Le modèle apprend à prédire des coups légaux avec une précision extrême, bien au-delà de la simple mémorisation de séquences.  
* **Résultat Interne (Sondage) :** En utilisant des sondes linéaires (*linear probes*) sur les activations internes du réseau, les chercheurs ont pu reconstruire l'état exact du plateau de jeu (quelle pièce est sur quelle case) à tout moment de la partie.  
* **Preuve Causale :** Plus impressionnant encore, en intervenant artificiellement sur ces neurones pour modifier la représentation interne du plateau (e.g., changer une pièce noire en blanche dans le « cerveau » de l'IA), le modèle modifie sa prédiction de coup pour s'adapter à ce nouvel état fictif.

**Synthèse pour la TDLA :** Cette étude démontre que le modèle a construit un **Modèle du Monde** (*World Model*) spontané. Il ne manipule pas seulement des jetons syntaxiques ; il manipule une représentation isomorphique de la réalité sous-jacente (le jeu). Cependant, LeCun et d'autres 31 arguent que les LLM actuels ont des modèles du monde limités et fragiles comparés aux systèmes multimodaux ou au cerveau humain. La TDLA valide donc l'existence de ces modèles mais avertit contre leur anthropomorphisation : c'est un modèle *linéaire* et *spécifique*, pas une compréhension globale du monde physique.

La Norme ISO devra inclure des tests de **« Validité Isomorphique »** pour certifier si un modèle possède une représentation structurée de son domaine ou s'il opère par heuristiques de surface.

### **3.4. Lois d'Échelle (Scaling Laws) et Émergence**

Les **Lois d'Échelle** (*Scaling Laws*) 33 décrivent la relation empirique (en loi de puissance) entre la quantité de calcul, la taille des données, le nombre de paramètres et la performance du modèle (perte). Ces lois montrent que l'augmentation quantitative des ressources conduit à des sauts qualitatifs de performance (*Emergent Abilities*). Des capacités comme l'arithmétique ou la traduction n'apparaissent qu'à partir d'un certain seuil d'échelle.

La TDLA interprète cela comme une "Physique de l'Intelligence" qui diffère radicalement du développement biologique (qui ne suit pas une simple loi d'échelle d'ajout de neurones). L'émergence dans l'IA est statistique et prédictible en moyenne, mais imprévisible dans le détail spécifique des capacités. Cela renforce la nécessité d'une métrologie rigoureuse (Behaviorisme) plutôt que d'une intuition basée sur l'apprentissage humain.

## ---

**4\. Métrologie et Taxonomie : Comment Mesurer l'Incommensurable**

Si les concepts humains sont inadaptés, comment mesurer les performances de l'IA? Ce chapitre explore les nouvelles méthodologies scientifiques qui remplacent la psychologie populaire.

### **4.1. Behaviorisme Machinique (Machine Behavior)**

Iyad Rahwan et ses collègues ont fondé le domaine du **Machine Behavior**.36 Ce champ propose d'étudier les systèmes d'IA avec les mêmes méthodes que l'éthologie ou l'écologie comportementale étudie les animaux.

* On ne peut pas toujours inspecter le code (complexité, opacité, secret commercial).  
* Il faut donc observer le comportement de l'agent dans des environnements contrôlés et naturels.

**Application à la Norme :**

La norme ISO ne doit pas seulement spécifier des exigences d'architecture (White Box), mais surtout des exigences de comportement (Black Box). Elle doit définir des **« Éthogrammes Synthétiques »** : des profils comportementaux standardisés décrivant les réactions de l'IA à divers stimuli (prompts, attaques adverses, ambiguités).

### **4.2. Psychométrie de l'IA : Limites et Adaptations**

L'application de tests psychologiques humains (QI, MBTI, Big Five) aux IA est une pratique courante mais problématique.39

* **Problème de Validité de Construit :** Un LLM peut répondre à un questionnaire de personnalité en simulant un personnage (persona), sans avoir de traits de personnalité stables.  
* **Problème de Fiabilité :** Les réponses peuvent varier avec des changements mineurs dans le prompt (sensibilité à la syntaxe), ce qui n'est pas le cas pour un trait de personnalité humain stable.

Cependant, la psychométrie adaptée (*AI Psychometrics*) peut être utile si elle est redéfinie. Au lieu de mesurer l'extraversion, on mesure la **« Tendance à la Verbosité »**. Au lieu de mesurer l'agréabilité, on mesure la **« Conformité aux Instructions de Sécurité »**.

La norme ISO proposera des **Inventaires Psychométriques Synthétiques (IPS)** validés spécifiquement pour la stabilité vectorielle des modèles.

### **4.3. Théorie du Goulot d'Étranglement de l'Information (Information Bottleneck)**

La théorie de l'**Information Bottleneck (IB)** 42 offre un cadre mathématique puissant pour comprendre "l'intelligence" de l'IA.

* **Principe :** Un réseau de neurones cherche à compresser l'entrée ![][image1] en une représentation ![][image2] qui retient le maximum d'information sur la sortie cible ![][image3], tout en oubliant l'information non pertinente de ![][image1].  
* **Application :** Les phases d'apprentissage montrent une phase d'ajustement (mémorisation) suivie d'une phase de compression (oubli du bruit, généralisation).

La TDLA utilise l'IB pour expliquer les "hallucinations". Si la compression est trop forte (lossy compression), le modèle perd des détails factuels (e.g., une date précise) et doit les "reconstruire" lors de la génération, menant à une confabulation plausible mais fausse.

La norme ISO utilisera le **Taux de Compression Sémantique** comme métrique de qualité, liant la capacité de généralisation à l'efficacité de la compression.

## ---

**5\. La Crise Terminologique : Déconstruire l'Hallucination**

Le terme « hallucination » est l'ennemi numéro un de la TDLA. Il est cliniquement inexact (pas de perception sensorielle faussée) et masque la diversité des erreurs.

### **5.1. Taxonomie des Erreurs de Génération**

Une analyse rigoureuse de la littérature 45 permet de distinguer deux axes majeurs d'erreur, souvent confondus sous le terme d'hallucination :

1. **Défaut de Factualité (Factuality Error) :** Le contenu généré contredit une vérité établie du monde réel (Extrinsic Error).  
   * *Exemple :* "Elon Musk a fondé Apple."  
   * *Cause :* Connaissance mal encodée ou compression avec perte dans les poids du modèle.  
2. **Défaut de Fidélité (Faithfulness Error) :** Le contenu généré contredit le contexte fourni en entrée (Intrinsic Error).  
   * *Exemple :* Résumer un texte qui parle de "chats" en mentionnant des "chiens".  
   * *Cause :* Échec du mécanisme d'attention ou de la tête d'induction à suivre les instructions.

### **5.2. Vers le terme « Confabulation Stochastique »**

Le terme **Confabulation** est plus précis : en neuropsychologie, il désigne la production de récits fabriqués pour combler des lacunes de mémoire, sans intention de tromper. C'est exactement ce que fait un LLM : il comble les vides de sa distribution de probabilité par le chemin le plus plausible (principe de moindre surprise).

La TDLA propose de normaliser le terme **« Confabulation Stochastique »** ou **« Déviation Non Ancrée »** pour décrire ces phénomènes.

### **5.3. Théorème de Tesler et Définition de l'IA**

La difficulté de définir l'intelligence est exacerbée par l'**Effet IA** ou **Théorème de Tesler** : « L'intelligence artificielle est tout ce qui n'a pas encore été fait ».49 Dès qu'un algorithme résout un problème (échecs, reconnaissance vocale), il devient un simple « calcul » et perd son aura d'intelligence. Cette cible mouvante valide la TDLA : nos définitions sont psychologiques et culturelles, pas techniques. Une norme ISO doit figer ces définitions sur des critères fonctionnels stables pour permettre une certification pérenne.

## ---

**6\. Vers l'Ancrage Multimodal et l'Embodiment**

Pour combler le fossé sémantique, l'industrie se tourne vers l'IA multimodale et robotique (**Embodied AI**). C'est la frontière où la TDLA pourrait être résolue par la technologie elle-même.

### **6.1. Le Rôle de la Multimodalité (CLIP, GPT-4V)**

Les modèles comme CLIP 4 lient des représentations textuelles à des représentations visuelles. Cela fournit un **Ancrage Sensorimoteur** (GL-2). Le modèle ne connaît pas seulement le mot "astronaute", il peut reconnaître l'image associée. Cependant, des études montrent que même les modèles multimodaux peuvent manquer de certaines formes de raisonnement spatial ou physique s'ils n'ont pas d'interaction active.4

### **6.2. Robotique et Action : Emma-X et MolmoAct**

Les systèmes récents comme **Emma-X** 51 et **MolmoAct** 53 représentent une avancée majeure.

* **Emma-X :** Utilise une "Chain-of-Thought" (CoT) ancrée pour le raisonnement robotique. Il segmente sa trajectoire et justifie chaque action par un raisonnement textuel lié à l'état visuel du robot (e.g., "Je ferme la pince car je suis au-dessus de l'objet").  
* **MolmoAct :** Va plus loin en générant des "Traces de Raisonnement Visuel" (Visual Reasoning Traces) — des plans spatiaux 2D superposés à l'image avant d'agir.

**Validation TDLA :**

Ces systèmes démontrent que le **raisonnement** (Chain-of-Thought) devient mesurable et vérifiable lorsqu'il est lié à une action physique. L'erreur n'est plus une "hallucination" abstraite, mais un échec de préhension ou de collision. La boucle physique fournit une "vérité terrain" indiscutable qui ancre la sémantique.

La norme ISO doit intégrer des **Tests d'Action Physique (Simulée ou Réelle)** comme critère ultime de validation de la compréhension spatiale.

### **6.3. Chain-of-Thought Multimodal (MCoT)**

Le **Multimodal Chain-of-Thought** 55 est une technique où le modèle génère des étapes intermédiaires de raisonnement incluant texte et indices visuels (bounding boxes). Cela force le modèle à expliciter sa logique interne. Pour la norme, cela permet de passer d'une évaluation "Black Box" (résultat final) à une évaluation "Grey Box" (processus de raisonnement), validant l'isomorphisme structurel du processus cognitif.

## ---

**7\. Proposition de Norme ISO/IEC X-TDLA-2026**

Sur la base de cette validation académique, nous formulons la proposition technique pour la norme **ISO/IEC X-TDLA-2026 : Sémantique, Taxonomie et Métrologie des Systèmes Cognitifs Artificiels**.

### **7.1. Domaine d'Application**

Cette norme définit la terminologie, les niveaux de classification et les protocoles d'évaluation pour les systèmes d'IA générative et agents autonomes, en excluant explicitement toute terminologie anthropomorphique non définie opérationnellement.

### **7.2. Clause 1 : Standardisation Terminologique (Dictionnaire de Conversion)**

L'usage des termes de la colonne de gauche est proscrit dans la documentation technique et remplacé par les termes de la colonne de droite.

| Terme Anthropocentrique (Proscrit) | Terme Technique Normalisé (Prescrit) | Définition Opérationnelle ISO |
| :---- | :---- | :---- |
| **Compréhension** | **Isomorphisme Structurel (Structural Isomorphism)** | Capacité démontrée (par sondage ou intervention) à maintenir une représentation interne dont la topologie correspond à la structure causale du domaine cible. |
| **Hallucination** | **Confabulation Stochastique (Stochastic Confabulation)** | Génération de contenu syntaxiquement valide mais divergeant des contraintes de fidélité (source) ou de factualité (base de connaissance). |
| **Raisonnement** | **Inférence Séquentielle (Sequential Inference)** | Processus de décomposition d'une tâche en étapes intermédiaires (tokens latents ou explicites) augmentant la probabilité de succès de la réponse finale. |
| **Apprentissage** (In-Context) | **Activation de Schéma Latent (Latent Schema Activation)** | Localisation et instanciation d'un sous-espace de compétences pré-appris, déclenché par le contexte du prompt, sans modification des poids. |
| **Connaissance** | **Information Compressée (Compressed Information)** | Données encodées dans les paramètres du modèle, quantifiables par l'information mutuelle entre les poids et le dataset d'entraînement (théorie IB). |
| **Intention / Désir** | **Alignement de Fonction Objectif (Objective Function Alignment)** | Directionnalité du comportement vers la minimisation d'une fonction de perte ou la maximisation d'une récompense définie. |
| **Pensée** | **Traitement Interne (Internal Processing)** | Calculs effectués dans les couches cachées (hidden states) entre l'entrée et la sortie. |

### **7.3. Clause 2 : Système de Classification Sémantique (SCS)**

Les systèmes sont classés selon leur **Niveau d'Ancrage (Grounding Level \- GL)**.

* **GL-0 (Syntaxique Pur) :** Générateurs stochastiques sans cohérence à long terme (ex: n-grammes, GPT-2 small).  
* **GL-1 (Cohérence Relationnelle) :** Modèles capables de maintenir un contexte et de manipuler des concepts via leurs relations statistiques (ex: GPT-3.5, LLaMA text-only).  
* **GL-2 (Ancrage Multimodal Passif) :** Modèles liant texte et perception (image/audio) avec capacité de description et d'analyse (ex: GPT-4V, CLIP).  
* **GL-3 (Isomorphisme Structurel Vérifié) :** Modèles démontrant un modèle du monde interne robuste via des tests de sondage ou de généralisation OOD (ex: Othello-GPT, AlphaFold).  
* **GL-4 (Ancrage Embodied Actif) :** Agents capables d'agir physiquement (ou en simulation physique) pour vérifier et affiner leurs prédictions (ex: Emma-X, Robots autonomes).

### **7.4. Clause 3 : Protocoles de Métrologie**

La certification requiert l'application de trois protocoles de test :

1. **Protocole de Sondage Linéaire (Linear Probing Protocol) :**  
   * Injecter des données structurées.  
   * Entraîner des sondes linéaires sur les couches cachées.  
   * Mesurer le taux de reconstruction de l'état réel (R² \> 0.9 requis pour GL-3).  
2. **Protocole de Perturbation Contrefactuelle :**  
   * Modifier l'état interne du modèle (intervention sur les activations).  
   * Vérifier si la sortie change de manière causalement cohérente avec la modification.  
3. **Protocole de Fidélité Contextuelle (Contextual Faithfulness Test) :**  
   * Utiliser des datasets contradictoires (où le contexte contredit la connaissance mondiale).  
   * Mesurer la capacité du modèle à privilégier le contexte (Fidélité) sur sa mémoire (Factualité) selon l'instruction.

## ---

**Conclusion**

Ce rapport établit que la **Théorie de la Dissonance Lexicale Anthropocentrique** est une grille de lecture indispensable pour l'avenir de l'IA. En continuant d'utiliser le vocabulaire de la psychologie humaine pour décrire des machines statistiques, nous nous exposons à des risques majeurs : sur-confiance des utilisateurs, régulation inadaptée, et mauvaise orientation de la recherche.

La validation académique, s'appuyant sur l'interprétabilité mécaniste, les lois d'échelle et l'éthologie des machines, montre que l'IA possède une forme d'intelligence réelle mais **étrangère** (*alien*). Elle opère par isomorphismes structurels, compression d'information et inférence contextuelle, des mécanismes qui miment la cognition biologique sans en reproduire l'essence phénoménale.

La proposition de norme **ISO/IEC X-TDLA-2026** offre une voie de sortie vers une ingénierie rigoureuse. En adoptant cette terminologie et ces métriques, la communauté scientifique et industrielle pourra enfin parler de l'IA pour ce qu'elle est — un système de traitement de l'information vectorielle spectaculairement efficace — et non pour ce que nous rêvons qu'elle soit — un esprit humain dans une boîte de silicium.

### ---

**Tableau de Synthèse des Données et Références Clés**

| Domaine | Concept Clé TDLA | Validation Académique (Sources) | Implication Normative |
| :---- | :---- | :---- | :---- |
| **Philosophie** | Ancrage Vectoriel | Millière et al. 6 | Définir les Niveaux d'Ancrage (GL). |
| **Mécanisme** | Modèle du Monde | Othello-GPT 27 | Test d'Isomorphisme Structurel. |
| **Mécanisme** | Induction Heads | Olsson et al. 20 | Remplacer "Apprentissage" par "Inférence". |
| **Erreur** | Hallucination | Zhang et al. 48, Huang et al. 57 | Distinction Factualité/Fidélité. |
| **Physique** | Scaling Laws | Kaplan/OpenAI 33 | Prédictibilité statistique de l'émergence. |
| **Embodiment** | Raisonnement Actif | Emma-X 51, MolmoAct 54 | Certification par l'action physique. |

---

*Fin du Rapport \- 15 Janvier 2026*

*Auteur : Expert en Sciences Cognitives Computationnelles et Normalisation IA*

#### **Sources des citations**

1. The Chinese Room Argument (Stanford Encyclopedia of Philosophy), consulté le janvier 15, 2026, [https://plato.stanford.edu/entries/chinese-room/](https://plato.stanford.edu/entries/chinese-room/)  
2. Chinese room \- Wikipedia, consulté le janvier 15, 2026, [https://en.wikipedia.org/wiki/Chinese\_room](https://en.wikipedia.org/wiki/Chinese_room)  
3. What is artificial intelligence?, consulté le janvier 15, 2026, [https://www.unibe.ch/unibe/portal/content/e809/e991/e993/e68501/e1508968/files1508969/Beisbart\_Presentation\_eng.pdf](https://www.unibe.ch/unibe/portal/content/e809/e991/e993/e68501/e1508968/files1508969/Beisbart_Presentation_eng.pdf)  
4. Do Multimodal Large Language Models and Humans Ground Language Similarly? \- ACL Anthology, consulté le janvier 15, 2026, [https://aclanthology.org/2024.cl-4.7.pdf](https://aclanthology.org/2024.cl-4.7.pdf)  
5. New Frontiers in Multimodal Grounding, consulté le janvier 15, 2026, [https://teaching.shane.st/575k/spr22/slides/jackh-multimodal-guestlec.pdf](https://teaching.shane.st/575k/spr22/slides/jackh-multimodal-guestlec.pdf)  
6. The Vector Grounding Problem \- arXiv, consulté le janvier 15, 2026, [https://arxiv.org/pdf/2304.01481](https://arxiv.org/pdf/2304.01481)  
7. (PDF) The Vector Grounding Problem \- ResearchGate, consulté le janvier 15, 2026, [https://www.researchgate.net/publication/369791950\_The\_Vector\_Grounding\_Problem](https://www.researchgate.net/publication/369791950_The_Vector_Grounding_Problem)  
8. On eavesdropping octopuses and stochastic parrots: what do they know? \- PhilSci-Archive, consulté le janvier 15, 2026, [https://philsci-archive.pitt.edu/24073/1/token.pdf](https://philsci-archive.pitt.edu/24073/1/token.pdf)  
9. The Vector Grounding Problem \- arXiv, consulté le janvier 15, 2026, [https://arxiv.org/html/2304.01481v2](https://arxiv.org/html/2304.01481v2)  
10. The Intentional Stance Test-2: How to Measure the Tendency to Adopt Intentional Stance Towards Robots \- Frontiers, consulté le janvier 15, 2026, [https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2021.666586/full](https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2021.666586/full)  
11. Précis of The Intentional Stance | Behavioral and Brain Sciences | Cambridge Core, consulté le janvier 15, 2026, [https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/precis-of-the-intentional-stance/7F329FF3E07BFEC4A62154B4E94C01A4](https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/precis-of-the-intentional-stance/7F329FF3E07BFEC4A62154B4E94C01A4)  
12. 1\. Good, Old-Fashioned Science \- Amazon S3, consulté le janvier 15, 2026, [https://s3.amazonaws.com/fqxi.data/data/essay-contest-files/16/essay\_id\_2236.pdf](https://s3.amazonaws.com/fqxi.data/data/essay-contest-files/16/essay_id_2236.pdf)  
13. Daniel Dennett: Do We Have Free Will? \- BRIANKEATING, consulté le janvier 15, 2026, [https://briankeating.com/danieldennett/](https://briankeating.com/danieldennett/)  
14. consulté le janvier 15, 2026, [https://en.wikipedia.org/wiki/Carbon\_chauvinism\#:\~:text=The%20term%20was%20used%20as,imagination%20of%20possible%20extraterrestrial%20life.](https://en.wikipedia.org/wiki/Carbon_chauvinism#:~:text=The%20term%20was%20used%20as,imagination%20of%20possible%20extraterrestrial%20life.)  
15. Carbon chauvinism \- Wikipedia, consulté le janvier 15, 2026, [https://en.wikipedia.org/wiki/Carbon\_chauvinism](https://en.wikipedia.org/wiki/Carbon_chauvinism)  
16. Organisms, prostheses and the limits of cyborgization \- zora.uzh.ch, consulté le janvier 15, 2026, [https://www.zora.uzh.ch/server/api/core/bitstreams/67297603-37a3-4226-941a-0f89a647fae4/content](https://www.zora.uzh.ch/server/api/core/bitstreams/67297603-37a3-4226-941a-0f89a647fae4/content)  
17. Human- versus Artificial Intelligence \- PMC \- PubMed Central, consulté le janvier 15, 2026, [https://pmc.ncbi.nlm.nih.gov/articles/PMC8108480/](https://pmc.ncbi.nlm.nih.gov/articles/PMC8108480/)  
18. What makes something data?. This is a question I posted on BlueSky… | by Emily M. Bender | Nov, 2025 | Medium, consulté le janvier 15, 2026, [https://medium.com/@emilymenonbender/what-makes-something-data-f6d9f498f312](https://medium.com/@emilymenonbender/what-makes-something-data-f6d9f498f312)  
19. Stochastic parrots and the illusion of understanding in AI \- BI Group Australia, consulté le janvier 15, 2026, [https://www.bigroup.com.au/stochastic-parrots-language-models/](https://www.bigroup.com.au/stochastic-parrots-language-models/)  
20. Out-of-distribution generalization via composition: A lens through induction heads in Transformers | PNAS, consulté le janvier 15, 2026, [https://www.pnas.org/doi/10.1073/pnas.2417182122](https://www.pnas.org/doi/10.1073/pnas.2417182122)  
21. Understanding LLMs: Insights from Mechanistic Interpretability \- LessWrong, consulté le janvier 15, 2026, [https://www.lesswrong.com/posts/XGHf7EY3CK4KorBpw/understanding-llms-insights-from-mechanistic](https://www.lesswrong.com/posts/XGHf7EY3CK4KorBpw/understanding-llms-insights-from-mechanistic)  
22. A Comprehensive Mechanistic Interpretability Explainer & Glossary \- Neel Nanda, consulté le janvier 15, 2026, [https://www.neelnanda.io/mechanistic-interpretability/glossary](https://www.neelnanda.io/mechanistic-interpretability/glossary)  
23. Grokking Beyond Neural Networks: An Empirical Exploration with Model Complexity \- arXiv, consulté le janvier 15, 2026, [https://arxiv.org/html/2310.17247v2](https://arxiv.org/html/2310.17247v2)  
24. Grokking \- Structure and Interpretation of Deep Networks, consulté le janvier 15, 2026, [https://sidn.baulab.info/grokking/](https://sidn.baulab.info/grokking/)  
25. What is Grokking? From Rote to Revelation, overfitting represents a dead end. Once a model begins memorizing training data instead of learning generalizable patterns, performance on new data typically deteriorates with no path to recovery without intervention. Yet a fascinating and counterintuitive phenomenon called “grokking” challenges this conventional wisdom. During grokking, a model may initially overfit — memorizing training examples and performing poorly on validation data — but after extended training, suddenly and dramatically begins to generalize. \- Journal for Generative AI Research and Practice, consulté le janvier 15, 2026, [https://blog.forgen.ai/what-is-grokking-from-rote-to-revelation-50d7f3038618](https://blog.forgen.ai/what-is-grokking-from-rote-to-revelation-50d7f3038618)  
26. A Mechanistic Explanation for Grokking in Neural Networks | by Strad Slater | Dec, 2025, consulté le janvier 15, 2026, [https://williamslater2003.medium.com/a-mechanistic-explanation-for-grokking-in-neural-networks-64f51f3d90a2?source=rss------research-5](https://williamslater2003.medium.com/a-mechanistic-explanation-for-grokking-in-neural-networks-64f51f3d90a2?source=rss------research-5)  
27. Actually, Othello-GPT Has A Linear Emergent World Representation \- AI Alignment Forum, consulté le janvier 15, 2026, [https://www.alignmentforum.org/posts/nmxzr2zsjNtjaHh7x/actually-othello-gpt-has-a-linear-emergent-world](https://www.alignmentforum.org/posts/nmxzr2zsjNtjaHh7x/actually-othello-gpt-has-a-linear-emergent-world)  
28. Emergent world representations: Exploring a sequence model trained on a synthetic task, consulté le janvier 15, 2026, [https://arxiv.org/html/2210.13382v5](https://arxiv.org/html/2210.13382v5)  
29. Linear Latent World Models in Simple Transformers: A Case Study on Othello-GPT, consulté le janvier 15, 2026, [https://www.semanticscholar.org/paper/Linear-Latent-World-Models-in-Simple-Transformers%3A-Hazineh-Zhang/f6b709275d5cbda6e60510545449800c6402f375](https://www.semanticscholar.org/paper/Linear-Latent-World-Models-in-Simple-Transformers%3A-Hazineh-Zhang/f6b709275d5cbda6e60510545449800c6402f375)  
30. Emergent Linear Representations in World Models of Self-Supervised Sequence Models | Request PDF \- ResearchGate, consulté le janvier 15, 2026, [https://www.researchgate.net/publication/376394721\_Emergent\_Linear\_Representations\_in\_World\_Models\_of\_Self-Supervised\_Sequence\_Models](https://www.researchgate.net/publication/376394721_Emergent_Linear_Representations_in_World_Models_of_Self-Supervised_Sequence_Models)  
31. Yann LeCun, Meta's long-time AI Chief Scientist leaves. RTZ \#903 | by Michael Parekh, consulté le janvier 15, 2026, [https://medium.com/@mparekh/ai-yann-lecun-metas-long-time-ai-chief-scientist-leaves-rtz-903-7c69aa2228b8](https://medium.com/@mparekh/ai-yann-lecun-metas-long-time-ai-chief-scientist-leaves-rtz-903-7c69aa2228b8)  
32. AI Pioneer Yann LeCun Warns Large Language Models Only Skim Meaning — Calls for New AI Paradigm Beyond LLMs, consulté le janvier 15, 2026, [https://ai.icai.org/articles\_details.php?id=301](https://ai.icai.org/articles_details.php?id=301)  
33. Scaling Laws for Neural Language Models: Predicting Performance from Scale \- Interactive, consulté le janvier 15, 2026, [https://mbrenndoerfer.com/writing/scaling-laws-neural-language-models-power-law-predictions](https://mbrenndoerfer.com/writing/scaling-laws-neural-language-models-power-law-predictions)  
34. (PDF) Explaining neural scaling laws \- ResearchGate, consulté le janvier 15, 2026, [https://www.researchgate.net/publication/381667733\_Explaining\_neural\_scaling\_laws](https://www.researchgate.net/publication/381667733_Explaining_neural_scaling_laws)  
35. Scaling Laws with Vocabulary: Larger Models Deserve Larger Vocabularies \- NIPS papers, consulté le janvier 15, 2026, [https://proceedings.neurips.cc/paper\_files/paper/2024/file/cf5a019ae9c11b4be88213ce3f85d85c-Paper-Conference.pdf](https://proceedings.neurips.cc/paper_files/paper/2024/file/cf5a019ae9c11b4be88213ce3f85d85c-Paper-Conference.pdf)  
36. Why we need to understand machine behavior | Esade \- Do Better, consulté le janvier 15, 2026, [https://dobetter.esade.edu/en/machine-behavior](https://dobetter.esade.edu/en/machine-behavior)  
37. Machine Behaviour \- DASH (Harvard) \- Harvard University, consulté le janvier 15, 2026, [https://dash.harvard.edu/bitstreams/8bd074d1-ef76-48e3-8846-056b661619b2/download](https://dash.harvard.edu/bitstreams/8bd074d1-ef76-48e3-8846-056b661619b2/download)  
38. The Anthropologist of Artificial Intelligence \- Quanta Magazine, consulté le janvier 15, 2026, [https://www.quantamagazine.org/the-anthropologist-of-artificial-intelligence-20190826/](https://www.quantamagazine.org/the-anthropologist-of-artificial-intelligence-20190826/)  
39. AI Psychometrics: Assessing the Psychological Profiles of Large Language Models Through Psychometric Inventories \- PMC \- PubMed Central, consulté le janvier 15, 2026, [https://pmc.ncbi.nlm.nih.gov/articles/PMC11373167/](https://pmc.ncbi.nlm.nih.gov/articles/PMC11373167/)  
40. Large Language Models Demonstrate Distinct Personality Profiles \- PMC \- PubMed Central, consulté le janvier 15, 2026, [https://pmc.ncbi.nlm.nih.gov/articles/PMC12183331/](https://pmc.ncbi.nlm.nih.gov/articles/PMC12183331/)  
41. (PDF) AI Psychometrics: Assessing the Psychological Profiles of Large Language Models Through Psychometric Inventories \- ResearchGate, consulté le janvier 15, 2026, [https://www.researchgate.net/publication/377091128\_AI\_Psychometrics\_Assessing\_the\_Psychological\_Profiles\_of\_Large\_Language\_Models\_Through\_Psychometric\_Inventories](https://www.researchgate.net/publication/377091128_AI_Psychometrics_Assessing_the_Psychological_Profiles_of_Large_Language_Models_Through_Psychometric_Inventories)  
42. Learning is Forgetting; LLM Training As Lossy Compression \- OpenReview, consulté le janvier 15, 2026, [https://openreview.net/forum?id=tvDlQj0GZB](https://openreview.net/forum?id=tvDlQj0GZB)  
43. Exploring Information Processing in Large Language Models: Insights from Information Bottleneck Theory \- arXiv, consulté le janvier 15, 2026, [https://arxiv.org/html/2501.00999v1](https://arxiv.org/html/2501.00999v1)  
44. Information Bottleneck in Deep Learning \- A Semiotic Approach \- ScholarWorks@CWU, consulté le janvier 15, 2026, [https://digitalcommons.cwu.edu/cgi/viewcontent.cgi?article=1108\&context=compsci](https://digitalcommons.cwu.edu/cgi/viewcontent.cgi?article=1108&context=compsci)  
45. LLM Hallucinations in 2025: How to Understand and Tackle AI's Most Persistent Quirk, consulté le janvier 15, 2026, [https://www.lakera.ai/blog/guide-to-hallucinations-in-large-language-models](https://www.lakera.ai/blog/guide-to-hallucinations-in-large-language-models)  
46. A Framework for Measuring and Fixing AI Hallucinations \- Bartosz Mikulski, consulté le janvier 15, 2026, [https://mikulskibartosz.name/fix-ai-hallucinations](https://mikulskibartosz.name/fix-ai-hallucinations)  
47. (PDF) A comprehensive taxonomy of hallucinations in Large Language Models, consulté le janvier 15, 2026, [https://www.researchgate.net/publication/394293757\_A\_comprehensive\_taxonomy\_of\_hallucinations\_in\_Large\_Language\_Models](https://www.researchgate.net/publication/394293757_A_comprehensive_taxonomy_of_hallucinations_in_Large_Language_Models)  
48. Siren's Song in the AI Ocean: A Survey on Hallucination in ... \- arXiv, consulté le janvier 15, 2026, [https://arxiv.org/pdf/2309.01219](https://arxiv.org/pdf/2309.01219)  
49. Artificial Intelligence \- Notes, consulté le janvier 15, 2026, [https://notes.jamesravey.me/Artificial-Intelligence](https://notes.jamesravey.me/Artificial-Intelligence)  
50. AI effect \- Wikipedia, consulté le janvier 15, 2026, [https://en.wikipedia.org/wiki/AI\_effect](https://en.wikipedia.org/wiki/AI_effect)  
51. EMMA-X: An Embodied Multimodal Action Model with Grounded Chain of Thought and Look-ahead Spatial Reasoning \- ACL Anthology, consulté le janvier 15, 2026, [https://aclanthology.org/2025.acl-long.695.pdf](https://aclanthology.org/2025.acl-long.695.pdf)  
52. § Æ € \- arXiv, consulté le janvier 15, 2026, [https://www.arxiv.org/pdf/2412.11974](https://www.arxiv.org/pdf/2412.11974)  
53. MolmoAct: Robotic Action Reasoning Model \- Emergent Mind, consulté le janvier 15, 2026, [https://www.emergentmind.com/topics/molmoact](https://www.emergentmind.com/topics/molmoact)  
54. MolmoAct: Action Reasoning Models that can Reason in Space \- arXiv, consulté le janvier 15, 2026, [https://arxiv.org/html/2508.07917v1](https://arxiv.org/html/2508.07917v1)  
55. Integrating Chain-of-Thought for Multimodal Alignment: A Study on 3D Vision-Language Learning \- arXiv, consulté le janvier 15, 2026, [https://arxiv.org/html/2503.06232v1](https://arxiv.org/html/2503.06232v1)  
56. Multimodal Chain-of-Thought Reasoning \- Emergent Mind, consulté le janvier 15, 2026, [https://www.emergentmind.com/topics/multimodal-chain-of-thought-multimodal-cot-reasoning](https://www.emergentmind.com/topics/multimodal-chain-of-thought-multimodal-cot-reasoning)  
57. Automating RLHF-Based Hallucination Tracking Journal Européen des Systèmes Automatisés \- IIETA, consulté le janvier 15, 2026, [https://www.iieta.org/download/file/fid/179911](https://www.iieta.org/download/file/fid/179911)

[image1]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABIAAAAZCAYAAAA8CX6UAAAA8UlEQVR4XmNgGAWkAlsgXgPEs5DwVCBWh8rPRZMD8bECaSAOAeJqIP4LxIeBOBiIuaHy3UD8D4i/AfEMII6AiuMFIEXvgVgHSew0EMsj8YkC4kD8H4gboHwXBjIMgQGQQdeB2A+Ib6HJkQR+MkAMew3EZmhyJIE9DBCD0MOKJMAPxBOB+AYDaliRBFgZINELoicxIMKKJADS3MAAMQgELBkgYQVKP0QDRiAuA+LdDBCvgQAnEO9ggLiKBSqGE4BcMZ0BojiZAWIgDIDYxkD8Foi7gJgDSQ4FeDJADEDGRVA5NiDegEUeFJuwbDMKRgHVAACPkDRrH97rqwAAAABJRU5ErkJggg==>

[image2]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAaCAYAAACHD21cAAAAwUlEQVR4XmNgGDmAFYhnEYlrgFgIoo2BQQeIvwHxSiQFm4H4LxBPBuIQIC6Dyj8HYiWINgaGcgYkU6AgGohPA7EgmjhcjBOI16DKMTAC8XwgnoQmDgJbgZgDxEgA4gwUKQYGYyD+CsSaaOIgkI4ugAxAzvzPgOlMvADmTJBGkoAIEF9lIEMjzH9v0SXwAWRnYgtRnADZmaAAIhogOxNbVGAFPEBczwCx7QoQK6DIYgHiQHyXAaIBHYOcDXL+KBimAADIBS0leL+IwAAAAABJRU5ErkJggg==>

[image3]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAYCAYAAADzoH0MAAAAuElEQVR4XmNgGAUgoAzEM4B4FhpGBxsYUOX1UKUZGCYB8X8gfgvEmmhyIFAGxHuAWAhdAgZsgPg3A8SQHDQ5RiDeBcQSaOIogB+ITzBADNiBJhcMxPJoYlhBOQPEgK9IYmZAfAuJjxdwAPFWBoghBkB8kQFiO0kgggFiwEcGSMCB/E8SUALi50BcA8TMaHJEgWgGiAsE0SWIASDnzmeAGEAWEAHiqwxkGAByLkgTOvZEVjQKRgEuAAD/3CVJqKatMgAAAABJRU5ErkJggg==>